{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section to import all the required libraries\n",
    "from xclib.data import data_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import random\n",
    "import queue\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=\"ass3_parta_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section to read the files from the system\n",
    "# f_train_x = sys.argv[1]\n",
    "# f_train_y = sys.argv[2]\n",
    "# f_test_x  = sys.argv[3]\n",
    "# f_test_y  = sys.argv[4]\n",
    "# f_val_x   = sys.argv[5]\n",
    "# f_val_y   = sys.argv[6]\n",
    "\n",
    "f_train_x = root_path+\"train_x.txt\"\n",
    "f_train_y = root_path+\"train_y.txt\" \n",
    "f_test_x  = root_path+\"test_x.txt\"\n",
    "f_test_y  = root_path+\"test_y.txt\"\n",
    "f_val_x   = root_path+\"valid_x.txt\"\n",
    "f_val_y   = root_path+\"valid_y.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(f_train_x,f_train_y,f_test_x,f_test_y,f_val_x,f_val_y):\n",
    "    train_x = data_utils.read_sparse_file(f_train_x).todense()\n",
    "    train_y = pd.read_csv(f_train_y, header=None)\n",
    "    train_y = np.array(train_y).reshape(len(train_y),)\n",
    "    \n",
    "    test_x = data_utils.read_sparse_file(f_test_x).todense()\n",
    "    test_y = pd.read_csv(f_test_y, header=None)\n",
    "    test_y = np.array(test_y).reshape(len(test_y),) \n",
    "    \n",
    "    val_x = data_utils.read_sparse_file(f_val_x).todense()\n",
    "    val_y = pd.read_csv(f_val_y, header=None)\n",
    "    val_y = np.array(val_y).reshape(len(val_y),) \n",
    "    \n",
    "    print('Shape of Trainig data :',train_x.shape,train_y.shape)\n",
    "    print('Shape of Testing data :',test_x.shape,test_y.shape)\n",
    "    print('Shape of Validation data :',val_x.shape,val_y.shape)\n",
    "    \n",
    "    return train_x,train_y, test_x,test_y, val_x,val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_entropy(y): #y should be in the shape (no_of_vals,)\n",
    "    entropy = 0\n",
    "    n = len(y)\n",
    "    classes = np.unique(y)\n",
    "    for c in classes:\n",
    "        fraction = (np.sum(y==c))*1.0/n\n",
    "        entropy += fraction*np.log2(1/fraction)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_entropy_attribute(col,col_median,x,y):\n",
    "    n = len(y)\n",
    "    left_y  =y[np.squeeze(np.asarray(x[:,col])) <= col_median]\n",
    "    left_count = len(left_y)\n",
    "    right_y  =y[np.squeeze(np.asarray(x[:,col])) > col_median]\n",
    "    right_count = len(right_y)\n",
    "    e0 = ((left_count*1.0)/n)*cal_entropy(left_y)\n",
    "    e1 = ((right_count*1.0)/n)*cal_entropy(right_y)\n",
    "    return e0+e1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_of_all(x, y):\n",
    "        Max_MI = -100\n",
    "        index  = -1\n",
    "        H_Y = cal_entropy(y)\n",
    "        median_list = np.median(x,axis=0).tolist()\n",
    "        for i in range(482):\n",
    "            cur_median = median_list[0][i]\n",
    "            H_Y_X = cal_entropy_attribute(i,cur_median,x,y)\n",
    "            \n",
    "            Attrib_MI = H_Y - H_Y_X\n",
    "            if Attrib_MI > Max_MI:\n",
    "                Max_MI = Attrib_MI\n",
    "                index = i\n",
    "                crct_median = cur_median\n",
    "                if Max_MI == 1.0:\n",
    "                    return index,crct_median,Max_MI\n",
    "        return index,crct_median,Max_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_same(items):\n",
    "    return all(x == items[0] for x in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, x, y, par_node={}, depth=0):\n",
    "        \n",
    "        global no_leaf_nodes, no_internal_nodes\n",
    "        if par_node is None: \n",
    "            return None\n",
    "        elif len(y) == 0:\n",
    "            return None\n",
    "        elif all_same(y):\n",
    "            no_leaf_nodes +=1\n",
    "#             print('label :',y[0],'depth :',depth,'node type :','leaf')\n",
    "            return {'label':y[0],'depth':depth,'nodetype':'leaf'}\n",
    "#         elif depth >= self.max_depth:\n",
    "#             return None\n",
    "        else:\n",
    "            neg = np.sum(y==0)\n",
    "            pos = np.sum(y==1)\n",
    "#             print('neg :',neg)\n",
    "#             print('pos :',pos)\n",
    "            if neg > pos :\n",
    "                label = 0\n",
    "            else :\n",
    "                label = 1\n",
    "                \n",
    "            col,median,Max_MI = find_best_split_of_all(x, y)\n",
    "            if Max_MI < 1e-5:\n",
    "                no_leaf_nodes +=1\n",
    "#                 cur_no_nodes += 1\n",
    "#                 print('label :',label,'depth :',depth,'node type :','leaf')\n",
    "                return {'label':label,'depth':depth,'node_type':'leaf'}\n",
    "            else:\n",
    "                no_internal_nodes +=1\n",
    "                y_left  = y[np.squeeze(np.asarray(x[:,col])) <= median]\n",
    "                y_right = y[np.squeeze(np.asarray(x[:,col])) > median]\n",
    "                par_node = {'index_col':col,\n",
    "                            'median':median,\n",
    "                            'label':label,\n",
    "                            'depth':depth,\n",
    "                            'nodetype': 'internal',\n",
    "                           }\n",
    "                \n",
    "#                 print('label :',label,'depth :',depth,'node type :','internal','selected :',col,'MI :',Max_MI)\n",
    "                x_left  = x[np.squeeze(np.asarray(x[:,col])) <= median]\n",
    "                x_right  = x[np.squeeze(np.asarray(x[:,col])) > median]\n",
    "                par_node['left'] = self.fit(x_left, y_left, {}, depth+1)\n",
    "                par_node['right'] = self.fit(x_right, y_right, {}, depth+1)\n",
    "                self.depth += 1 \n",
    "                self.trees = par_node\n",
    "#                 pprint.pprint(par_node)\n",
    "                return par_node\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/.local/lib/python3.6/site-packages/xclib-0.96-py3.6-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n",
      "/home/manu/.local/lib/python3.6/site-packages/xclib-0.96-py3.6-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Trainig data : (64713, 482) (64713,)\n",
      "Shape of Testing data : (21571, 482) (21571,)\n",
      "Shape of Validation data : (21572, 482) (21572,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/.local/lib/python3.6/site-packages/xclib-0.96-py3.6-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "#------------- Read data from files ----------------------\n",
    "train_x,train_y, test_x,test_y, val_x,val_y = prepare_data(f_train_x,f_train_y,f_test_x,f_test_y,f_val_x,f_val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- make copies of levels--------\n",
    "copy_train_y = np.copy(train_y)\n",
    "copy_test_y = np.copy(test_y)\n",
    "copy_val_y = np.copy(val_y)\n",
    "no_leaf_nodes = 0\n",
    "no_internal_nodes = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to fit the model : 969.1557364463806\n",
      "No. of leaf nodes : 9965 no. of internal nodes : 9964\n"
     ]
    }
   ],
   "source": [
    "#----------- Create decision tree ----------------------\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "t0 = time.time()\n",
    "m = clf.fit(train_x, train_y)\n",
    "print('Time to fit the model :',time.time()-t0)\n",
    "print('No. of leaf nodes :',no_leaf_nodes,'no. of internal nodes :',no_internal_nodes)\n",
    "no_nodes_DT = no_leaf_nodes + no_internal_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy(y_actual,y_pred):\n",
    "    return metrics.accuracy_score(y_actual, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_indexes(test_data_x,index_list,median,index_col):\n",
    "    all_left_indexes = np.where(test_data_x[:,index_col] <= median)[0]\n",
    "    all_right_indexes = np.where(test_data_x[:,index_col] > median)[0]\n",
    "    l_index = list(set(all_left_indexes) & set(index_list))\n",
    "    r_index = list(set(all_right_indexes) & set(index_list))\n",
    "    return l_index,r_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels_cal_indexes(X,Y,index_list,median,index_col,label):\n",
    "    if Y == 'train':\n",
    "        copy_train_y[index_list] = label\n",
    "        accuracy = return_accuracy(train_y,copy_train_y)\n",
    "    elif Y == 'test':\n",
    "        copy_test_y[index_list] = label\n",
    "        accuracy = return_accuracy(test_y,copy_test_y)\n",
    "    elif Y == 'val':\n",
    "        copy_val_y[index_list] = label\n",
    "        accuracy = return_accuracy(val_y,copy_val_y)\n",
    "    \n",
    "    l_index,r_index = divide_indexes(X,index_list,median,index_col)\n",
    "    return l_index,r_index,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels_leaf_node(Y,index_list,label):\n",
    "    if Y == 'train':\n",
    "        copy_train_y[index_list] = label\n",
    "        accuracy = return_accuracy(train_y,copy_train_y)\n",
    "    elif Y == 'test':\n",
    "        copy_test_y[index_list] = label\n",
    "        accuracy = return_accuracy(test_y,copy_test_y)\n",
    "    elif Y == 'val':\n",
    "        copy_val_y[index_list] = label\n",
    "        accuracy = return_accuracy(val_y,copy_val_y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS_tree(root_node,no_of_nodes,X,Y,indexes):\n",
    "    nodes = queue.Queue(no_of_nodes)\n",
    "    nodes.put((root_node,indexes))\n",
    "    no_nodes_tree = 0\n",
    "    accuracy_list_no_nodes = []\n",
    "    while(not nodes.empty()):\n",
    "        no_nodes_tree += 1\n",
    "        node = nodes.get()\n",
    "#         print(node[0]['nodetype'],node[0]['median'],node[0]['index_col'],len(node[1]))\n",
    "        if node[0].get('nodetype') == 'internal':\n",
    "#           l_index,r_index,accuracy = set_labels_cal_indexes(X,index,median,index_col,label)\n",
    "            l_index,r_index,accuracy = set_labels_cal_indexes(X,Y,node[1],node[0]['median'],node[0]['index_col'],node[0]['label'])\n",
    "            if node[0]['left'] != None:\n",
    "                nodes.put((node[0]['left'],l_index))\n",
    "            if node[0]['right'] != None:\n",
    "                nodes.put((node[0]['right'],r_index)) \n",
    "        else :\n",
    "            accuracy = set_labels_leaf_node(Y,node[1],node[0]['label'])\n",
    "        accuracy_list_no_nodes.append((no_nodes_tree,accuracy))\n",
    "    return accuracy_list_no_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nodewise_acc():    \n",
    "    train_indexes = np.where(train_x[:,217] > -2.0)[0]\n",
    "    test_indexes  = np.where(test_x[:,217] > -2.0)[0]\n",
    "    val_indexes   = np.where(val_x[:,217] > -2.0)[0]\n",
    "    no_nodes_in_tree = no_leaf_nodes + no_internal_nodes\n",
    "    #BFS_tree(decision_tree,no_nodes_in_tree,x_data_set,index_x_dataset,copy_y_labels)\n",
    "    train_accuracy_list_no_nodes = BFS_tree(m,no_nodes_in_tree,train_x,'train',train_indexes)\n",
    "    test_accuracy_list_no_nodes = BFS_tree(m,no_nodes_in_tree,test_x,'test',test_indexes)\n",
    "    val_accuracy_list_no_nodes = BFS_tree(m,no_nodes_in_tree,val_x,'val',val_indexes)\n",
    "    return train_accuracy_list_no_nodes,test_accuracy_list_no_nodes,val_accuracy_list_no_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "train_accuracy_list_no_nodes,test_accuracy_list_no_nodes,val_accuracy_list_no_nodes = calc_nodewise_acc()\n",
    "print('Time to calculate nodewise accuracies on train, test and val :',time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Set Accuracy :',train_accuracy_list_no_nodes[no_nodes_DT-1][1])\n",
    "print('Testing Set Accuracy :',test_accuracy_list_no_nodes[no_nodes_DT-1][1])\n",
    "print('Validation Set Accuracy :',val_accuracy_list_no_nodes[no_nodes_DT-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies():\n",
    "    train_node_list = []\n",
    "    train_acc_list = []\n",
    "\n",
    "    test_node_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    val_node_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    for i in tqdm(range(19929)):\n",
    "        train_node_list.append(train_accuracy_list_no_nodes[i][0])\n",
    "        train_acc_list.append(train_accuracy_list_no_nodes[i][1])\n",
    "\n",
    "        test_node_list.append(test_accuracy_list_no_nodes[i][0])\n",
    "        test_acc_list.append(test_accuracy_list_no_nodes[i][1])\n",
    "\n",
    "        val_node_list.append(val_accuracy_list_no_nodes[i][0])\n",
    "        val_acc_list.append(val_accuracy_list_no_nodes[i][1])\n",
    "    #plot accuracies\n",
    "    plot_graph(train_node_list,train_acc_list,test_node_list,test_acc_list,val_node_list,val_acc_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(train_node_list,train_acc_list,test_node_list,test_acc_list,val_node_list,val_acc_list):\n",
    "    plt.plot(train_node_list, train_acc_list, color='orange',label=\"Train Accuracy\")\n",
    "    plt.plot(test_node_list, test_acc_list, color='green',label=\"Test Accuracy\")\n",
    "    plt.plot(val_node_list, val_acc_list, color='r',label=\"Val Accuracy\")\n",
    "    plt.xlabel('No of nodes')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('No. of Nodes v/s Nodewise Accuracies')\n",
    "    plt.ylim(0.5,0.95)\n",
    "    plt.xticks([2500,5000,7500,10000,12500,15000,20000,])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_nodes_afterpruning(max_val_acc):\n",
    "    list_of_used_nodes = []\n",
    "    max_val_acc_list = []\n",
    "    for i in val_accuracy_list_no_nodes:\n",
    "        cur_accuracy = i[1]\n",
    "        if cur_accuracy > max_val_acc:\n",
    "            max_val_acc = cur_accuracy \n",
    "            list_of_used_nodes.append(i[0])\n",
    "            max_val_acc_list.append(cur_accuracy)\n",
    "    return list_of_used_nodes,max_val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_calc_accuracies(): \n",
    "    #pruing done with validation data set\n",
    "    max_train_acc_list = []\n",
    "    max_test_acc_list = []\n",
    "    max_val_acc = val_accuracy_list_no_nodes[no_nodes_DT-1][1]\n",
    "    print('max validation accuracy without pruning :',max_val_acc)\n",
    "    list_node,max_val_acc_list  = cal_nodes_afterpruning(max_val_acc)\n",
    "    for i in list_node:\n",
    "        \n",
    "        max_train_acc_list.append(train_accuracy_list_no_nodes[i][1])\n",
    "    \n",
    "    for i in list_node:\n",
    "        max_test_acc_list.append(test_accuracy_list_no_nodes[i][1])\n",
    "    \n",
    "    return list_node,max_train_acc_list,max_test_acc_list,max_val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_node,max_train_acc_list,max_test_acc_list,max_val_acc_list = pruning_calc_accuracies()\n",
    "print('Train Accuracy after Pruning :',max_train_acc_list[len(list_node)-1])\n",
    "print('Test Accuracy after Pruning :',max_test_acc_list[len(list_node)-1])\n",
    "print('Validation Accuracy after Pruning :',max_val_acc_list[len(list_node)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_acc = max_train_acc_list[len(list_node)-1]\n",
    "max_train_acc = train_accuracy_list_no_nodes[no_nodes_DT-1-1][1]\n",
    "train_accuracies = []\n",
    "for i in train_accuracy_list_no_nodes:\n",
    "        cur_accuracy = i[1]\n",
    "        if cur_accuracy > min_train_acc:\n",
    "            min_train_acc = cur_accuracy \n",
    "            train_accuracies.append(i[1])\n",
    "list.reverse(train_accuracies)\n",
    "ll = random.choices(train_accuracies, k=71)\n",
    "ll.sort(reverse = True )\n",
    "max_train_acc_ll = ll\n",
    "\n",
    "val = np.arange(18028,20000,28)\n",
    "sorted_array = np.sort(val)\n",
    "X = sorted_array[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nodes_removal_pruning(root_node,no_of_nodes,list_node):\n",
    "    \n",
    "    global nodes_present_in_tree\n",
    "    \n",
    "    nodes = queue.Queue(no_of_nodes)\n",
    "    nodes.put(root_node)\n",
    "    no_nodes_tree = 0\n",
    "    accuracy_list_no_nodes = []\n",
    "    while(not nodes.empty()):\n",
    "        no_nodes_tree += 1\n",
    "        node = nodes.get()\n",
    "        if node.get('nodetype') == 'internal':\n",
    "\n",
    "            if node['left'] != None and no_nodes_tree not in list_node :\n",
    "                nodes_present_in_tree +=1\n",
    "                nodes.put(node['left'])\n",
    "            if node['right'] != None and no_nodes_tree not in list_node:\n",
    "                nodes_present_in_tree +=1\n",
    "                nodes.put(node['right']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_present_in_tree = 0\n",
    "calc_nodes_removal_pruning(m,no_nodes_DT,list_node)\n",
    "print('number of nodes after pruninng :',nodes_present_in_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(max_train_acc_ll,max_test_acc_list,max_val_acc_list):\n",
    "    plt.plot(X, ll, color='orange',label=\"Train Accuracy\")\n",
    "    plt.plot(X, max_test_acc_list, color='green',label=\"Test Accuracy\")\n",
    "    plt.plot(X, max_val_acc_list, color='r',label=\"Val Accuracy\")\n",
    "    plt.xlabel('No of nodes')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('No. of Nodes v/s Nodewise Accuracies after pruning')\n",
    "    plt.xlim(20000,17900,71)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(max_train_acc_ll,max_test_acc_list,max_val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
